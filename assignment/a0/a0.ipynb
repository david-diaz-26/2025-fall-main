{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kDFiCs_0MaeI"
   },
   "source": [
    "# Assignment 0\n",
    "\n",
    "This notebook will help verify that you're all set up with the Python packages we'll be using this semester.\n",
    "\n",
    "**Your task:** just run the cells below, and verify that the output is as expected. If anything looks wrong, weird, or crashes, update your Python installation or contact the course staff. We don't want library issues to get in the way of the real coursework!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25451,
     "status": "ok",
     "timestamp": 1757309176540,
     "user": {
      "displayName": "David Diaz",
      "userId": "06202186365010675030"
     },
     "user_tz": 420
    },
    "id": "Rk5s0520MaeO",
    "outputId": "9f6eef14-b3af-4039-f9e2-e223988e7033",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version 2.0.2 is \n",
      "OK\n",
      "matplotlib version 3.10.0 is \n",
      "OK\n",
      "pandas version 2.2.2 is \n",
      "OK\n",
      "nltk version 3.9.1 is \n",
      "OK\n",
      "keras version 3.10.0 is \n",
      "OK\n",
      "tensorflow version 2.19.0 is \n",
      "OK\n",
      "transformers version 4.56.0 is \n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# Version checks\n",
    "import importlib\n",
    "def version_greater_equal(v1, v2):\n",
    "    for x, y in zip(v1.split('.'), v2.split('.')):\n",
    "        if int(x) != int(y):\n",
    "            return int(x) > int(y)\n",
    "    return True\n",
    "\n",
    "assert version_greater_equal('1.2.3', '0.1.1')\n",
    "assert version_greater_equal('1.2.3', '0.5.1')\n",
    "assert version_greater_equal('1.2.3', '1.2.3')\n",
    "assert version_greater_equal('0.22.0', '0.20.3')\n",
    "assert not version_greater_equal('1.1.1', '1.2.3')\n",
    "assert not version_greater_equal('0.5.1', '1.2.3')\n",
    "assert not version_greater_equal('0.20.3', '0.22.0')\n",
    "\n",
    "def version_check(libname, min_version):\n",
    "    m = importlib.import_module(libname)\n",
    "    print (\"%s version %s is \" % (libname, m.__version__))\n",
    "    print (\"OK\"\n",
    "           if version_greater_equal(m.__version__, min_version)\n",
    "           else \"out-of-date. Please upgrade!\")\n",
    "\n",
    "version_check(\"numpy\", \"2.0.2\")\n",
    "version_check(\"matplotlib\", \"3.10.0\")\n",
    "version_check(\"pandas\", \"2.2.2\")\n",
    "version_check(\"nltk\", \"3.9.1\")\n",
    "version_check(\"keras\", \"3.10.0\")\n",
    "version_check(\"tensorflow\", \"2.19.0\")\n",
    "version_check(\"transformers\", \"4.55.4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJeLTePaMaeT"
   },
   "source": [
    "## TensorFlow\n",
    "\n",
    "We'll be using [TensorFlow](tensorflow.org) to build deep learning models this semester. TensorFlow is a whole programming system in itself, based around the idea of a computation graph and deferred execution. We'll be talking a lot more about it in Assignment 1, but for now you should just test that it loads on your system.\n",
    "\n",
    "Run the cell below; you should see:\n",
    "```\n",
    "Hello, TensorFlow!\n",
    "42\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 81,
     "status": "ok",
     "timestamp": 1757309176628,
     "user": {
      "displayName": "David Diaz",
      "userId": "06202186365010675030"
     },
     "user_tz": 420
    },
    "id": "Yeo7loI7MaeU",
    "outputId": "5b3e90ea-d72d-4439-e102-3053a5360cce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, TensorFlow!\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "hello = tf.constant(\"Hello, TensorFlow!\")\n",
    "tf.print(hello)\n",
    "\n",
    "a = tf.constant(10)\n",
    "b = tf.constant(32)\n",
    "tf.print((a+b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6tpeOZp4MaeV"
   },
   "source": [
    "## NLTK\n",
    "\n",
    "[NLTK](http://www.nltk.org/) is a large compilation of Python NLP packages. It includes implementations of a number of classic NLP models, as well as utilities for working with linguistic data structures, preprocessing text, and managing corpora.\n",
    "\n",
    "NLTK is included with Anaconda, but the corpora need to be downloaded separately. Be warned that this will take up around 3.2 GB of disk space if you download everything! If this is too much, you can download individual corpora as you need them through the same interface.\n",
    "\n",
    "Type the following into a Python shell on the command line. It'll open a pop-up UI with the downloader:\n",
    "\n",
    "```\n",
    "import nltk\n",
    "nltk.download()\n",
    "```\n",
    "\n",
    "Alternatively, you can download individual corpora by name. The cell below will download the famous [Reuters-21578 benchmark corpus](https://kdd.ics.uci.edu/databases/reuters21578/reuters21578.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 830,
     "status": "ok",
     "timestamp": 1757309177460,
     "user": {
      "displayName": "David Diaz",
      "userId": "06202186365010675030"
     },
     "user_tz": 420
    },
    "id": "WibuBpFrMaeW",
    "outputId": "08e7ab22-7b32-4feb-c1b8-5097c28786ad"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
      "[nltk_data] Downloading package reuters to /root/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "assert(nltk.download('punkt'))\n",
    "assert(nltk.download('punkt_tab'))\n",
    "assert(nltk.download('reuters'))  # should return True if successful, or already installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TvBDxW_LMaeX"
   },
   "source": [
    "Now we can look at a few sentences. Expect to see:\n",
    "```\n",
    "ASIAN EXPORTERS FEAR DAMAGE FROM U . S .- JAPAN RIFT Mounting trade friction between the U . S . And Japan has raised fears among many of Asia ' s exporting nations that the row could inflict far - reaching economic damage , businessmen and officials said .\n",
    "\n",
    "They told Reuter correspondents in Asian capitals a U . S . Move against Japan might boost protectionist sentiment in the U . S . And lead to curbs on American imports of their products .\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 773,
     "status": "ok",
     "timestamp": 1757309178236,
     "user": {
      "displayName": "David Diaz",
      "userId": "06202186365010675030"
     },
     "user_tz": 420
    },
    "id": "_GweB4zRMaeX",
    "outputId": "204ddb85-f2f3-4428-ef4f-be54dc638342"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASIAN EXPORTERS FEAR DAMAGE FROM U . S .- JAPAN RIFT Mounting trade friction between the U . S . And Japan has raised fears among many of Asia ' s exporting nations that the row could inflict far - reaching economic damage , businessmen and officials said .\n",
      "\n",
      "They told Reuter correspondents in Asian capitals a U . S . Move against Japan might boost protectionist sentiment in the U . S . And lead to curbs on American imports of their products .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import reuters\n",
    "# Look at the first two sentences\n",
    "for s in reuters.sents()[:2]:\n",
    "    print(\" \".join(s))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WjYOd3vQMaeY"
   },
   "source": [
    "NLTK also includes a sample of the [Penn treebank](https://www.cis.upenn.edu/~treebank/), which we'll be using later in the course for parsing and part-of-speech tagging. Here's a sample of sentences, and an example tree. Expect to see:\n",
    "```\n",
    "The top money funds are currently yielding well over 9 % .\n",
    "\n",
    "(S\n",
    "  (NP-SBJ (DT The) (JJ top) (NN money) (NNS funds))\n",
    "  (VP\n",
    "    (VBP are)\n",
    "    (ADVP-TMP (RB currently))\n",
    "    (VP (VBG yielding) (NP (QP (RB well) (IN over) (CD 9)) (NN %))))\n",
    "  (. .))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 180,
     "status": "ok",
     "timestamp": 1757309178412,
     "user": {
      "displayName": "David Diaz",
      "userId": "06202186365010675030"
     },
     "user_tz": 420
    },
    "id": "ONFIsI-aMaeZ",
    "outputId": "78e38289-0ad2-4f0f-c3c3-4e89d75c2631"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/treebank.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The top money funds are currently yielding well over 9 % .\n",
      "\n",
      "(S\n",
      "  (NP-SBJ (DT The) (JJ top) (NN money) (NNS funds))\n",
      "  (VP\n",
      "    (VBP are)\n",
      "    (ADVP-TMP (RB currently))\n",
      "    (VP (VBG yielding) (NP (QP (RB well) (IN over) (CD 9)) (NN %))))\n",
      "  (. .))\n"
     ]
    }
   ],
   "source": [
    "assert(nltk.download(\"treebank\"))  # should return True if successful, or already installed\n",
    "print(\"\")\n",
    "from nltk.corpus import treebank\n",
    "# Look at the parse of a sentence.\n",
    "# Don't worry about what this means yet!\n",
    "idx = 45\n",
    "print(\" \".join(treebank.sents()[idx]))\n",
    "print(\"\")\n",
    "print(treebank.parsed_sents()[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OcQzQGo9Maea"
   },
   "source": [
    "We can also look at the [Europarl corpus](http://www.statmt.org/europarl/), which consists of *parallel* text - a sentence and its translations to multiple languages. You should see:\n",
    "```\n",
    "ENGLISH: Resumption of the session I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999 , and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period .\n",
    "```\n",
    "and its translation into French and Spanish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 591,
     "status": "ok",
     "timestamp": 1757309179004,
     "user": {
      "displayName": "David Diaz",
      "userId": "06202186365010675030"
     },
     "user_tz": 420
    },
    "id": "MGOrVrQtMaeb",
    "outputId": "9c4f536c-df1a-4544-e96d-1ea36bae6773"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package europarl_raw to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/europarl_raw.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ENGLISH: Resumption of the session I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999 , and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period .\n",
      "\n",
      "FRENCH: Reprise de la session Je déclare reprise la session du Parlement européen qui avait été interrompue le vendredi 17 décembre dernier et je vous renouvelle tous mes vux en espérant que vous avez passé de bonnes vacances .\n",
      "\n",
      "SPANISH: Reanudación del período de sesiones Declaro reanudado el período de sesiones del Parlamento Europeo , interrumpido el viernes 17 de diciembre pasado , y reitero a Sus Señorías mi deseo de que hayan tenido unas buenas vacaciones .\n"
     ]
    }
   ],
   "source": [
    "assert(nltk.download(\"europarl_raw\"))  # should return True if successful, or already installed\n",
    "print(\"\")\n",
    "from nltk.corpus import europarl_raw\n",
    "\n",
    "idx = 0\n",
    "\n",
    "print(\"ENGLISH: \" + \" \".join(europarl_raw.english.sents()[idx]))\n",
    "print(\"\")\n",
    "print(\"FRENCH: \" + \" \".join(europarl_raw.french.sents()[idx]))\n",
    "print(\"\")\n",
    "print(\"SPANISH: \" + \" \".join(europarl_raw.spanish.sents()[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1757309179008,
     "user": {
      "displayName": "David Diaz",
      "userId": "06202186365010675030"
     },
     "user_tz": 420
    },
    "id": "f6aRtMyvMaeb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
